{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911b9b99-f1d3-4595-b98c-8d614c8d2a2a",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "I'm going to try and collect a number of \"utility functions\" - these are Python functions that'll help me run various custom operations, like Prompt Graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce67c5-0786-4a3e-bef7-776c511e6a35",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of this notebook.\n",
    "\n",
    "We'll start with some import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7c3b1a-065e-4817-96fb-355b616e5e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\anaconda3\\envs\\ldm\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import statements\n",
    "import torch\n",
    "import open_clip\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from natsort import os_sorted\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "from scipy.spatial.distance import cosine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e4975-302f-4bfb-aee6-51ee5bcf7312",
   "metadata": {},
   "source": [
    "Next, we'll change our working directory to the root of the `stable-diffusion/` folder - this'll help us emulate the environment the `prompt-graph-utils.py` file will be run from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60efd2f-5819-473e-8c00-94c21e3d26bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Personal-Study\\Programming\\sd-prompt-graph\\stable-diffusion\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a069bd7-37d2-46e0-8c5a-a1cbc9c0e070",
   "metadata": {},
   "source": [
    "Finally, we're going to load in the OpenCLIP model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3aeeee9-ee06-4c1f-9bf5-a34e586bd6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the model used \n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32-quickgelu', pretrained='laion400m_e32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9111263b-1b32-43aa-8e77-721430a4973c",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e5553-1709-463d-9786-4c516b479106",
   "metadata": {},
   "source": [
    "### Text-Related SD Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1233aa-3181-489c-81d8-86ab426c769e",
   "metadata": {},
   "source": [
    "#### `txt_2_image()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "303ad334-042e-40cf-9660-8b622ebd8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will generate \n",
    "def txt_2_image(prompt, outdir=None, steps=55, height=512, width=512, seed=None, sample_amount=1, \n",
    "                file_name=None, latent_json_output_path=None, print_command=False, \n",
    "                return_latent_ndarray=True, return_pixels=False,\n",
    "                display_image=False, delete_img=False, delete_latent_json=False, turbo=True):\n",
    "    \n",
    "    # Generate the command \n",
    "    outdir_str = f'--outdir \"{outdir}\"' if outdir is not None else \"\"\n",
    "    filename_str = f'--file-name \"{file_name}\"' if file_name is not None else \"\"\n",
    "    latent_json_output_str = f'--latent-save-path \"{latent_json_output_path}\"' if latent_json_output_path is not None else \"\"\n",
    "    seed_str = f'--seed {seed}' if seed is not None else \"\"\n",
    "    command = f'python optimizedSD/optimized_txt2img.py --prompt \"{prompt}\" --H {height} --W {width} {seed_str} --n_samples {sample_amount} --ddim_steps {steps} {outdir_str} {filename_str} {latent_json_output_str} {\"--turbo\" if turbo else \"\"}'\n",
    "    \n",
    "    # Running the command\n",
    "    if (print_command):\n",
    "        print(f\"Running the following command:\\n{command}\\n\")\n",
    "    subprocess.run(command)\n",
    "    \n",
    "    # Determine where the resulting image was output \n",
    "    if (outdir is not None and file_name is not None):\n",
    "        resulting_img_file_path = Path(outdir) / Path(f\"{file_name}.png\")\n",
    "        \n",
    "        # Opening the image that was just created\n",
    "        img = Image.open(resulting_img_file_path)\n",
    "        img_pixels = np.array(img)\n",
    "\n",
    "        # Delete the image if we need to \n",
    "        if (delete_img):\n",
    "            os.remove(resulting_img_file_path)\n",
    "\n",
    "        # Display the image if it was \n",
    "        if (display_image):\n",
    "            display(img)\n",
    "        \n",
    "        # If we need to return the pixels, return them \n",
    "        if (return_pixels):\n",
    "            return img_pixels\n",
    "        \n",
    "        # If we're returning the latent ndarray, we'll need to load it \n",
    "        if (return_latent_ndarray and latent_json_output_path is not None):\n",
    "            with open(latent_json_output_path, \"r\") as json_file:\n",
    "                latent_ndarray = np.asarray(json.load(json_file))\n",
    "                \n",
    "            if (delete_latent_json):\n",
    "                os.remove(latent_json_output_path)\n",
    "            return latent_ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52a446-f511-4529-8240-142cf375ad64",
   "metadata": {},
   "source": [
    "#### `txt_latent_path_2_image()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58e37e4-6542-4326-be4f-8d50c7cf93fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will generate \n",
    "def txt_latent_path_2_image(txt_latent_path, outdir=None, file_name=None, steps=55, height=512, width=512, seed=None, sample_amount=1, \n",
    "                            print_command=False, return_latent_ndarray=True, return_pixels=False, display_image=False, \n",
    "                            delete_img=False, turbo=True, return_filename=False, return_clip_embedding=False):\n",
    "    \n",
    "    # Generate the command \n",
    "    outdir_str = f'--outdir \"{outdir}\"' if outdir is not None else \"\"\n",
    "    filename_str = f'--file-name \"{file_name}\"' if file_name is not None else \"\"\n",
    "    # latent_json_output_str = f'--latent-save-path \"{latent_json_output_path}\"' if latent_json_output_path is not None else \"\"\n",
    "    seed_str = f'--seed {seed}' if seed is not None else \"\"\n",
    "    command = f'python optimizedSD/prompt-graph-txt2latent.py --latent-json-path \"{txt_latent_path}\" --H {height} --W {width} {seed_str} --n_samples {sample_amount} --ddim_steps {steps} {outdir_str} {filename_str} {\"--turbo\" if turbo else \"\"}'\n",
    "    \n",
    "    # Running the command\n",
    "    if (print_command):\n",
    "        print(f\"Running the following command:\\n{command}\\n\")\n",
    "    subprocess.run(command)\n",
    "    \n",
    "    # Determine where the resulting image was output \n",
    "    if (outdir is not None and file_name is not None):\n",
    "        resulting_img_file_path = Path(outdir) / Path(f\"{file_name}.png\")\n",
    "        \n",
    "        # Opening the image that was just created\n",
    "        img = Image.open(resulting_img_file_path)\n",
    "        img_pixels = np.array(img)\n",
    "\n",
    "        # Delete the image if we need to \n",
    "        if (delete_img):\n",
    "            os.remove(resulting_img_file_path)\n",
    "\n",
    "        # Display the image if it was \n",
    "        if (display_image):\n",
    "            display(img)\n",
    "            \n",
    "        if (return_filename):\n",
    "            return resulting_img_file_path\n",
    "        \n",
    "        if (return_clip_embedding):\n",
    "            return image_path_to_clip_embedding(resulting_img_file_path)\n",
    "        \n",
    "        # If we need to return the pixels, return them \n",
    "        if (return_pixels):\n",
    "            return img_pixels\n",
    "        \n",
    "        # If we're returning the latent ndarray, we'll need to load it \n",
    "        if (return_latent_ndarray):\n",
    "            with open(txt_latent_path, \"r\") as json_file:\n",
    "                latent_ndarray = np.asarray(json.load(json_file))\n",
    "            return latent_ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0b0612-7719-4db7-8514-ebe9d9d08d62",
   "metadata": {},
   "source": [
    "#### `txt_latent_ndarray_2_image()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2954c52d-0cc3-4570-afb5-5b56f1bed6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_latent_ndarray_2_image(latent_ndarray, outdir=None, file_name=None, steps=55, height=512, width=512, seed=None, sample_amount=1, \n",
    "                               print_command=False, return_latent_ndarray=False, return_pixels=False, display_image=False, \n",
    "                               delete_img=False, turbo=True, return_filename=False, return_clip_embedding=False):\n",
    "    \n",
    "    output_latent_path = f\"outputs/temp_txt_latent_{int(datetime.now().timestamp())}.json\"\n",
    "    with open(output_latent_path, \"w\") as json_file:\n",
    "        json.dump(latent_ndarray.tolist(), json_file)\n",
    "\n",
    "    # Now, run the command\n",
    "    return_val = txt_latent_path_2_image(output_latent_path, outdir=outdir, file_name=file_name, steps=steps, height=height, width=width, seed=seed, sample_amount=sample_amount, \n",
    "                            print_command=print_command, return_latent_ndarray=return_latent_ndarray, return_pixels=return_pixels, \n",
    "                            display_image=display_image, delete_img=delete_img, turbo=turbo, return_filename=return_filename,\n",
    "                                         return_clip_embedding=return_clip_embedding)\n",
    "\n",
    "    # Remove the temporary latent\n",
    "    os.remove(output_latent_path)\n",
    "    \n",
    "    return return_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc11834-c09d-42af-819d-d195d3bfb9df",
   "metadata": {},
   "source": [
    "### Image-Related SD Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c72c192-df38-455e-af4e-d9d54bd2e357",
   "metadata": {},
   "source": [
    "#### `img_folder_2_latents()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6f5baf-a0a7-417b-9892-48f1695d4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_folder_2_latents(img_folder, outdir=None, turbo=True,\n",
    "                         delete_folder=True, return_ndarray_dict=True):\n",
    "    \n",
    "    # Craft the command that we're going to run \n",
    "    outdir_str = f'--outdir \"{outdir}\"' if outdir is not None else \"\"\n",
    "    command = f\"\"\"python .\\optimizedSD\\prompt-graph-img2latent.py --latent-from-img-folder \"{img_folder}\" {outdir_str} {'--turbo' if turbo else \"\"} \"\"\"\n",
    "    \n",
    "    # Run the command\n",
    "    subprocess.run(command)\n",
    "    \n",
    "    # Figure out where the latent .json was output to \n",
    "    latent_json_folder_name = \"img_latents\"\n",
    "    if outdir is None:\n",
    "        latent_json_folder_path = Path(\"outputs/img2img-samples/\") / Path(latent_json_folder_name)\n",
    "    else:\n",
    "        latent_json_folder_path = Path(outdir) / Path(latent_json_folder_name)\n",
    "    \n",
    "    \n",
    "    # If the return_ndarray flag is set, we're going to return a dictionary keyed by stem with the ndarrays\n",
    "    if (return_ndarray_dict):\n",
    "        ndarray_dict = {}\n",
    "        for file in latent_json_folder_path.iterdir():\n",
    "            if (file.suffix == \".json\"):\n",
    "                with open(file, \"r\") as json_file:\n",
    "                    latent_list = json.load(json_file)\n",
    "                    ndarray_dict[file.stem] = np.asarray(latent_list)\n",
    "                    \n",
    "        # If we want to delete the folder, we ought to do that \n",
    "        if (delete_folder):\n",
    "            shutil.rmtree(latent_json_folder_path)\n",
    "            \n",
    "        # Return the ndarray_dict\n",
    "        return ndarray_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa6b97-ea38-4db9-9081-d8bd9c8587a4",
   "metadata": {},
   "source": [
    "#### `img_2_latent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b6fe7f-2a2f-490a-817f-7672bb6265bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will run the img2latent script\n",
    "def img_2_latent(img_path, outdir=None, name=None, turbo=True,\n",
    "                 delete_file=True, return_ndarray=False):\n",
    "    \n",
    "    # Craft the command that we're going to run \n",
    "    outdir_str = f'--outdir \"{outdir}\"' if outdir is not None else \"\"\n",
    "    name_str = f'--name \"{name}\"' if name is not None else \"\"\n",
    "    command = f\"\"\"python .\\optimizedSD\\prompt-graph-img2latent.py --latent-from-img \"{img_path}\" {outdir_str} {name_str} {'--turbo' if turbo else \"\"} \"\"\"\n",
    "    \n",
    "    # Run the command\n",
    "    subprocess.run(command)\n",
    "    \n",
    "    # If the return_ndarray flag is set, we're going to return the ndarray\n",
    "    if (return_ndarray):\n",
    "        \n",
    "        # Figure out where the latent .json was output to \n",
    "        file_name = \"latent2img_output.json\"\n",
    "        if (name is not None):\n",
    "            file_name = f\"{name}.json\"\n",
    "        if outdir is None:\n",
    "            latent_json_path = Path(\"outputs/img2img-samples/\") / Path(file_name)\n",
    "        else:\n",
    "            latent_json_path = Path(outdir) / Path(file_name)\n",
    "            \n",
    "        # Read in the latent JSON\n",
    "        with open(latent_json_path, \"r\") as json_file:\n",
    "            latent_list = json.load(json_file)\n",
    "            latent_ndarray = np.asarray(latent_list)\n",
    "            \n",
    "        # Check to see if we need to delete the latent array \n",
    "        if (delete_file):\n",
    "            os.remove(latent_json_path)\n",
    "            \n",
    "        # Return the latent ndarray\n",
    "        return latent_ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743fa75c-a6cd-42e2-9e2d-b4e0fac9f481",
   "metadata": {},
   "source": [
    "#### `latent_2_img()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbb651d0-4d2f-4fdb-86fa-ca0b97fc5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will run the latent_2_img script\n",
    "def latent_2_img(latent_path=None, img_latent_ndarray=None, outdir=None, name=None, turbo=True,\n",
    "                 return_pixels=False, return_path=False, display_image=False, delete_file=False):\n",
    "    \n",
    "    # If the user didn't input an image path, and instead directly passed a latent in ndarray form, \n",
    "    # then we'll temporarily save this to a .json file \n",
    "    if (img_latent_ndarray is not None):\n",
    "        with open(\"outputs/temp_img_latent.json\", \"w\") as json_file:\n",
    "            json.dump(img_latent_ndarray.tolist(), json_file)\n",
    "        latent_path = \"outputs/temp_img_latent.json\"\n",
    "    \n",
    "    # Craft the command that we're going to run \n",
    "    outdir_str = f'--outdir \"{outdir}\"' if outdir is not None else \"\"\n",
    "    name_str = f'--name \"{name}\"' if name is not None else \"\"\n",
    "    command = f\"\"\"python .\\optimizedSD\\prompt-graph-latent2img.py --img-latent \"{latent_path}\" {outdir_str} {name_str} {'--turbo' if turbo else \"\"} \"\"\"\n",
    "    \n",
    "    # Run the command\n",
    "    subprocess.run(command)\n",
    "    \n",
    "    # If the temporary image latent was saved, we'll want to delete it \n",
    "    if (img_latent_ndarray is not None):\n",
    "        os.remove(latent_path)\n",
    "    \n",
    "    # Figure out where the resulting image was created\n",
    "    file_name = \"latent2img_outputImg.png\"\n",
    "    if (name is not None):\n",
    "        file_name = f\"{name}.png\"\n",
    "    if outdir is None:\n",
    "        latent_img_path = Path(\"outputs/img2img-samples/\") / Path(file_name)\n",
    "    else:\n",
    "        latent_img_path = Path(outdir) / Path(file_name)\n",
    "        \n",
    "    # Opening the image that was just created\n",
    "    img = Image.open(latent_img_path)\n",
    "    img_pixels = np.array(img)\n",
    "    \n",
    "    # Delete the image if we need to \n",
    "    if (delete_file):\n",
    "        os.remove(latent_img_path)\n",
    "    \n",
    "    # Display the image if it was \n",
    "    if (display_image):\n",
    "        display(img)\n",
    "    \n",
    "    # If return pixels is True, we're going to load in the new image\n",
    "    if (return_pixels):\n",
    "        return img_pixels\n",
    "    \n",
    "    if (return_path):\n",
    "        return latent_img_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdcf07-c883-437f-840c-60e63488c45d",
   "metadata": {},
   "source": [
    "#### `img_path_list_to_latents()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af7ddfa2-e9d0-4cab-aff4-2a6d67779397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will take a path of lists and return a dictionary of image latents keyed by \"filename stem\".\n",
    "# (TODO: Fix a bug in this where two images of the same name override eachother in the dictionary.)\n",
    "# This bug happens because I'm using file stems in the dictionary instead of full paths\n",
    "def img_path_list_to_latents(img_path_list):\n",
    "    \n",
    "    # We're first going to set up a temporary folder for these images\n",
    "    timestamp_suffix = str(int(datetime.utcnow().timestamp()))\n",
    "    img_tmp_folder_path = Path(f\"outputs/tmp_img_folder_{timestamp_suffix}\")\n",
    "    if (img_tmp_folder_path.exists()):\n",
    "        shutil.rmtree(img_tmp_folder_path)\n",
    "    img_tmp_folder_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # Now, we'll copy each of the images in the img_path_list to the temporary folder\n",
    "    for img_path in img_path_list:\n",
    "        new_path = img_tmp_folder_path / Path(img_path).name\n",
    "        shutil.copyfile(img_path, new_path)\n",
    "\n",
    "    # Next, we're going to run the img_folder_2_latents method \n",
    "    ndarray_dict = img_folder_2_latents(img_tmp_folder_path, \n",
    "                                        delete_folder=True, return_ndarray_dict=True)\n",
    "    \n",
    "    # Finally, we'll delete the img_tmp_folder_path now that we're done with it \n",
    "    shutil.rmtree(img_tmp_folder_path)\n",
    "\n",
    "    # Finally, we'll return this information \n",
    "    return ndarray_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe987470-b6e3-4432-a192-4e6a6df48c05",
   "metadata": {},
   "source": [
    "### Latent Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed907d-5e6f-4f94-b944-32586c23b5d9",
   "metadata": {},
   "source": [
    "#### `average_img_latents_from_path_list()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ccaceb5-a53f-4ba0-a87c-e6c5f259f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will average together the latents of the images whose paths are in img_file_path_list,\n",
    "# and return this \"average latent\" as an ndarray\n",
    "def average_img_latents_from_path_list(img_file_path_list):\n",
    "    \n",
    "    # We're going to store the latents in this dictionary \n",
    "    img_latents_by_stem_dict = {}\n",
    "    \n",
    "    # We're going to store the latents in this dictionary \n",
    "    img_latents_by_stem_dict = img_path_list_to_latents(img_file_path_list)\n",
    "\n",
    "    # Create the \"average\" of the latents \n",
    "    return np.mean([ndarray for stem, ndarray in img_latents_by_stem_dict.items()], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944e8b2-046e-4fee-928c-4350929f0518",
   "metadata": {},
   "source": [
    "#### `average_img_latents_from_img_folder()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "521e294d-3797-405d-ad14-5efc5018f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_img_latents_from_img_folder(img_folder_path):\n",
    "    return average_img_latents_from_path_list(\n",
    "        [file for file in Path(img_folder_path).iterdir() if file.suffix == \".png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c04a79-f275-407b-990b-9388dc412af0",
   "metadata": {},
   "source": [
    "### Various Utilites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4367ab3e-395e-42d6-b8b0-1e18cb3af68e",
   "metadata": {},
   "source": [
    "#### `change_in_filesize_paths()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29f6f652-719b-4cca-b68b-5b2a62fb7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will calculate the change in filesize between two image files\n",
    "def change_in_filesize_paths(file_1_path, file_2_path):\n",
    "    \n",
    "    # Make sure that both of the inputs are Path objects\n",
    "    file_1_path = Path(file_1_path)\n",
    "    file_2_path = Path(file_2_path)\n",
    "    \n",
    "    # Now, grab the filesizes \n",
    "    file_1_size = file_1_path.stat().st_size\n",
    "    file_2_size = file_2_path.stat().st_size\n",
    "    \n",
    "    # Get the absolute value of their difference, and compare it to file_1_size\n",
    "    filesize_diff_abs = abs(file_1_size - file_2_size)\n",
    "    return filesize_diff_abs/file_2_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7598095-0ff7-4abb-a467-ade5fcb93ebf",
   "metadata": {},
   "source": [
    "#### `change_in_filesize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cd49010-7553-4ddb-ab82-ea5afd49b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will calculate the change in filesize between two image files\n",
    "def change_in_filesize(file_1_size, file_2_size):\n",
    "    \n",
    "    # Get the absolute value of their difference, and compare it to file_1_size\n",
    "    filesize_diff_abs = abs(file_1_size - file_2_size)\n",
    "    return filesize_diff_abs/file_2_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6704086c-f6f8-486c-9ac3-1be8c4d547fe",
   "metadata": {},
   "source": [
    "#### `change_in_pixels_paths()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fd5f15e-3ff9-49ee-9cca-1e7262fa8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will calculate the change in pixel-space between two images \n",
    "def change_in_pixels_paths(file_1_path, file_2_path):\n",
    "    \n",
    "    # Make sure that both of the inputs are Path objects\n",
    "    file_1_path = Path(file_1_path)\n",
    "    file_2_path = Path(file_2_path)\n",
    "    \n",
    "    # Load the images into pixel arrays\n",
    "    file_1_pixels = np.asarray(Image.open(file_1_path))\n",
    "    file_2_pixels = np.asarray(Image.open(file_2_path))\n",
    "\n",
    "    # Now, calculate the difference in norm \n",
    "    return np.linalg.norm(file_1_pixels-file_2_pixels)/np.linalg.norm(file_1_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d0edf-2981-447c-a88b-8d0e7d6f68f5",
   "metadata": {},
   "source": [
    "#### ```change_in_pixels()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "784fcfb3-ea0d-4223-bfc1-93453308e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will calculate the change in pixel-space between two images \n",
    "def change_in_pixels(file_1_pixels, file_2_pixels):\n",
    "\n",
    "    # Now, calculate the difference in norm \n",
    "    return np.linalg.norm(file_1_pixels-file_2_pixels)/np.linalg.norm(file_1_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2be8c-9c9f-4997-9177-51ca2c0135ce",
   "metadata": {},
   "source": [
    "#### `change_in_latents_paths()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6acf6e9a-b758-48fe-bf80-32e3c1b256f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will calculate the change in latent-space between two images\n",
    "def change_in_latents_paths(file_1_path, file_2_path):\n",
    "    \n",
    "    # Use CLIP to grab the latents \n",
    "    path_stem_to_latents_dict = img_path_list_to_latents([file_1_path, file_2_path])\n",
    "    \n",
    "    # Make sure that both of the inputs are Path objects\n",
    "    file_1_path = Path(file_1_path)\n",
    "    file_2_path = Path(file_2_path)\n",
    "\n",
    "    # Now, grab the latents from the path_stem_to_latents_dict\n",
    "    file_1_latent = path_stem_to_latents_dict[file_1_path.stem]\n",
    "    file_2_latent = path_stem_to_latents_dict[file_2_path.stem]\n",
    "\n",
    "    # Return the difference\n",
    "    return np.linalg.norm(file_1_latent-file_2_latent)/np.linalg.norm(file_1_latent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c25024-648b-41b5-8c54-9b875893f6d4",
   "metadata": {},
   "source": [
    "#### `change_in_latents()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "122d136c-6f51-4cae-924e-e0d6f5ce178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will calculate the change in latent-space between two images\n",
    "def change_in_latents(file_1_latent, file_2_latent):\n",
    "\n",
    "    # Return the difference\n",
    "    return np.linalg.norm(file_1_latent-file_2_latent)/np.linalg.norm(file_1_latent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafdc18c-eb27-4f74-a593-ee34acd05112",
   "metadata": {},
   "source": [
    "#### CLIP Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "790111d0-c3d5-4ac6-a517-87bd7bb3e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will take in a path to an image and return the CLIP embedding of that image\n",
    "def image_path_to_clip_embedding(img_path):\n",
    "    \n",
    "    # Running this image through the CLIP pre-processor\n",
    "    image = preprocess(Image.open(img_path)).unsqueeze(0)\n",
    "\n",
    "    # Using CLIP to encode the image into a vector\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "    # Return the image features\n",
    "    return image_features[0]\n",
    "\n",
    "# This method will take in a list of image paths and return a dictionary (keyed by path stem)\n",
    "# of all of the CLIP embeddings for the images\n",
    "def image_path_list_to_clip_embedding_dict(img_path_list):\n",
    "    \n",
    "    # Create the dictionary we're going to return\n",
    "    img_embedding_dict = {}\n",
    "    \n",
    "    # Ensure that all of the paths in the img_path_list are Path objects\n",
    "    img_path_list = [Path(path) for path in img_path_list]\n",
    "    \n",
    "    # Iterate through each path, and calculate the CLIP embedding\n",
    "    for path in img_path_list:\n",
    "        img_embedding_dict[path.stem] = image_path_to_clip_embedding(path)\n",
    "        \n",
    "    # Return the dictionary\n",
    "    return img_embedding_dict\n",
    "\n",
    "# This method will calculate the cosine distance between two CLIP embeddings\n",
    "def change_in_clip_embedding(emb1, emb2):\n",
    "    return cosine(emb1, emb2)\n",
    "\n",
    "# This method will calculate the cosine distance between two CLIP embeddings (when given the paths of the images)\n",
    "def change_in_clip_embedding_paths(path1, path2):\n",
    "    emb1 = image_path_to_clip_embedding(path1)\n",
    "    emb2 = image_path_to_clip_embedding(path2)\n",
    "    return change_in_clip_embedding(emb1, emb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1edb6b8-0a80-439f-ba73-4ab170b243eb",
   "metadata": {},
   "source": [
    "### Prompt-Graph\n",
    "These utilities are directly related to prompt graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac6fe3c-c7da-405c-8569-300b42f93d4f",
   "metadata": {},
   "source": [
    "#### `prompt_info_for_frame()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e1c4c46-7b52-41d8-8519-520c5adc92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will generate a prompt for a particular frame from a configuration file\n",
    "def prompt_info_for_frame(frame, config):\n",
    "    \n",
    "    # Create a \"prompt_key_to_text_prompt\" dictionary\n",
    "    prompt_key_to_text_prompt = {prompt_info[\"key\"]: prompt_info[\"prompt\"] for prompt_info in config[\"prompts\"]}\n",
    "    prompt_strength_by_frame = config[\"prompt_strength_by_frame\"]\n",
    "    \n",
    "    # Iterate through the prompts to see which ones have non-null strengths\n",
    "    prompt_keys_to_use = []\n",
    "    for prompt_info in config[\"prompts\"]:\n",
    "        key = prompt_info[\"key\"]\n",
    "        if (prompt_strength_by_frame[str(frame)][str(key)] is not None):\n",
    "            prompt_keys_to_use.append(key)\n",
    "            \n",
    "    # If we didn't find any prompts w/ strengths associated with this frame, return None\n",
    "    if (not prompt_keys_to_use):\n",
    "        return None\n",
    "            \n",
    "    # Now, for each of the keys in the prompt key, we're going to \n",
    "    final_prompt = \" \".join([f\"{prompt_key_to_text_prompt[key].strip()}:{str(prompt_strength_by_frame[str(frame)][str(key)])}\"\n",
    "        for key in prompt_keys_to_use])\n",
    "    return final_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7cd513-4024-4afd-8463-769e048963c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### `rename_pics_in_folder_monotonically()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "745cbbdd-a481-433a-9bd7-9e9396f8f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will rename all of the pictures in a folder so that they're monotonically increasing from 0 based on alphabetical order\n",
    "def rename_pics_in_folder_monotonically(folder_path, prefix=\"\", stopping_point=None, rename_clip_latent=False):\n",
    "    \n",
    "    # Make sure this folder is a Path object\n",
    "    folder_path = Path(folder_path)\n",
    "    \n",
    "    # Iterate through each file in the folder, and collect their names \n",
    "    img_stems = []\n",
    "    for file_path in folder_path.iterdir():\n",
    "        if (file_path.suffix == \".png\"):\n",
    "            img_stems.append(file_path.stem)\n",
    "\n",
    "    # Sort them \n",
    "    img_stems = os_sorted(img_stems)\n",
    "    if (stopping_point is not None):\n",
    "        img_stems=img_stems[:stopping_point+1]\n",
    "        print(img_stems)\n",
    "    \n",
    "    # Now, we're going to rename all of the files twice. The first time, we're going to rename them all \n",
    "    rename_addition = len(img_stems)+1\n",
    "    for idx, stem in enumerate(img_stems):\n",
    "\n",
    "        # Grab the file at this index\n",
    "        cur_file = folder_path / Path(f\"{stem}.png\")\n",
    "        new_path = folder_path / Path(f\"{prefix}{idx+rename_addition}.png\")\n",
    "        os.rename(cur_file, new_path)\n",
    "        \n",
    "        if (rename_clip_latent):\n",
    "            cur_file_new = folder_path / Path(\"latent_json_folder\") / Path(f\"latent_json_{stem}.json\")\n",
    "            new_path_new = folder_path / Path(\"latent_json_folder\") / Path(f\"{prefix}latent_json_{idx+rename_addition}.json\")\n",
    "            os.rename(cur_file_new, new_path_new)\n",
    "        \n",
    "    for num in range(rename_addition, len(img_stems)+rename_addition):\n",
    "        \n",
    "        # Grab the file at this index\n",
    "        cur_file = folder_path / Path(f\"{prefix}{num}.png\")\n",
    "        new_path = folder_path / Path(f\"{prefix}{num-rename_addition}.png\")\n",
    "        os.rename(cur_file, new_path)\n",
    "        \n",
    "        if (rename_clip_latent):\n",
    "            cur_file = folder_path / Path(\"latent_json_folder\") / Path(f\"{prefix}latent_json_{num}.json\")\n",
    "            new_path = folder_path / Path(\"latent_json_folder\") / Path(f\"{prefix}latent_json_{num-rename_addition}.json\")\n",
    "            os.rename(cur_file, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10283788-0b61-4bd1-9d97-c4a87f2dc45f",
   "metadata": {},
   "source": [
    "#### `launch_config_generation()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00621bdd-68d2-4888-bd09-4d5b393498ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will launch a configuration from a given filepath\n",
    "def launch_config_generation(config_file_path, steps=55, height=512, width=512, seed=1,\n",
    "                             save_prompt_strength_plot=True, save_image_change_plot=True,\n",
    "                             image_change_plot_distance_metric=\"clip_embeddings\"):\n",
    "    \n",
    "    # Open the configuration file \n",
    "    with open(config_file_path, \"r\") as json_file:\n",
    "        config = json.load(json_file)\n",
    "\n",
    "    # Save the actual configuration file\n",
    "    config_file_save_path_folder = Path(f\"outputs\\\\txt2img-samples\\\\{config['filename']}\")\n",
    "    config_file_save_path_folder.mkdir(exist_ok=True, parents=True)\n",
    "    with open(f'{config_file_save_path_folder}/config.json', \"w\") as json_file:\n",
    "        json.dump(config, json_file, indent=2)\n",
    "    \n",
    "    config[\"filename\"] = f\"outputs\\\\txt2img-samples\\\\{config['filename']}\"\n",
    "    \n",
    "    # Create a folder for the latent JSONs within this new folder\n",
    "    latent_json_folder = Path(config[\"filename\"]) / Path(\"latent_json_folder\")\n",
    "    latent_json_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # Iterate through each frame and generate the image corresponding with it\n",
    "    for frame in tqdm(range(int(config[\"frame_amt\"]))):\n",
    "\n",
    "        # Generate the prompt for this frame\n",
    "        frame_prompt = prompt_info_for_frame(frame, config)\n",
    "\n",
    "        # If the frame_prompt is a valid string, run the generation for this frame\n",
    "        if (frame_prompt):\n",
    "            txt_2_image(frame_prompt, outdir=config[\"filename\"], steps=steps, height=height, width=width, seed=seed, \n",
    "                        file_name=str(frame), latent_json_output_path=f'{latent_json_folder}/latent_json_{frame}.json')\n",
    "            \n",
    "    # Now that we're at the end of the loop, we can rename everything\n",
    "    rename_pics_in_folder_monotonically(Path(config[\"filename\"]), rename_clip_latent=True)\n",
    "    \n",
    "    # If the save_prompt_strength_plot flag is True, then we'll save the prompt strength image \n",
    "    if (save_prompt_strength_plot):\n",
    "        \n",
    "        # Generate the Plotly figure \n",
    "        plotly_fig = generate_prompt_graph_image(config)\n",
    "        \n",
    "        # Determine what the filepath is \n",
    "        file_path = Path(config[\"filename\"]) / Path(\"Prompt Strength Graph.png\")\n",
    "        \n",
    "        # Save the Plotly figure that was just created \n",
    "        plotly_fig.write_image(file_path, format=\"png\", scale=3)\n",
    "        \n",
    "    # If the save_image_change_plot flag is True, then we'll save the image difference plot\n",
    "    if (save_image_change_plot):\n",
    "        \n",
    "        # Generate the prompt graph image difference figure\n",
    "        plotly_fig = generate_prompt_graph_image_difference_plotly_fig(Path(config[\"filename\"]), \n",
    "                                                                       distance_method=image_change_plot_distance_metric)\n",
    "        \n",
    "        # Determine what the filepath is \n",
    "        file_path = Path(config[\"filename\"]) / Path(\"Frame to Frame Difference Graph.png\")\n",
    "        \n",
    "        # Now, save the Plotly figure that was just created\n",
    "        plotly_fig.write_image(file_path, format=\"png\", scale=3)\n",
    "            \n",
    "    # Return the folder where we output all of the files\n",
    "    return config[\"filename\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e83a3db-4e92-45e2-b571-c4a7a3da7b93",
   "metadata": {},
   "source": [
    "#### `recursive_latent_interpolation()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b651035f-10f0-476f-8978-6d2b80308974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the different methods we're going to use to calculate distance\n",
    "distance_metric_keys = {\"filesize_paths\": change_in_filesize_paths,\n",
    "                        \"filesize\": change_in_filesize,\n",
    "                        \"pixels_paths\": change_in_pixels_paths,\n",
    "                        \"pixels\": change_in_pixels,\n",
    "                        \"latents_paths\": change_in_latents_paths,\n",
    "                        \"latents\": change_in_latents,\n",
    "                        \"clip_embeddings_paths\": change_in_clip_embedding_paths,\n",
    "                        \"clip_embeddings\": change_in_clip_embedding}\n",
    "\n",
    "# Set up a stub for the method \n",
    "def recursive_latent_interpolation(left_filename, right_filename, left_latent, right_latent, \n",
    "                                   left_measure=None, right_measure=None, direction=\"l\", early_stop=4, \n",
    "                                   pct_change_threshold=0.3, distance_metric=\"latents\", seed=1):\n",
    "\n",
    "    # ========================================================================\n",
    "    # Miscellaneous setup steps\n",
    "    # ========================================================================\n",
    "    # Make sure both the left_filename and right_filename are Paths \n",
    "    left_filename = Path(left_filename)\n",
    "    right_filename = Path(right_filename)\n",
    "\n",
    "    # ========================================================================\n",
    "    # Check if we're at an early stopping point\n",
    "    # ========================================================================\n",
    "    # Stop the recursion if we're at an early stopping point \n",
    "    if (early_stop is not None and early_stop <= 0):\n",
    "        return \n",
    "\n",
    "    # ========================================================================\n",
    "    # Generate a new filename for the new image\n",
    "    # ========================================================================\n",
    "    new_filename = f\"new\"\n",
    "    if (left_filename.stem.isnumeric() and right_filename.stem.isnumeric()):\n",
    "        new_filename = left_filename.stem + f\"_{early_stop}#m\"\n",
    "    else:\n",
    "        letter_to_add = \"a\" if direction == \"left\" else \"b\"\n",
    "        pair_to_add = f\"{early_stop}#{letter_to_add}\"\n",
    "        bigger_filename = left_filename.stem\n",
    "        if (len(right_filename.stem) > len(bigger_filename)):\n",
    "            bigger_filename = right_filename.stem\n",
    "        split_bigger_filename = bigger_filename.split(\"_\")\n",
    "\n",
    "        # Deal with the instance where our direction is \"left\"\n",
    "        if (direction == \"left\"):\n",
    "            split_bigger_filename.insert(1, pair_to_add)\n",
    "        elif (direction == \"right\"):\n",
    "            split_bigger_filename.append(pair_to_add)\n",
    "\n",
    "        # Generate the new filename \n",
    "        new_filename = \"_\".join(split_bigger_filename)\n",
    "\n",
    "    # ========================================================================\n",
    "    # Launch the new generation \n",
    "    # ========================================================================\n",
    "\n",
    "    # Generate an intermediate latent \n",
    "    intermediate_latent = np.mean([left_latent, right_latent], axis=0)\n",
    "    \n",
    "    # Now, we'll want to save this intermediate latent to the folder with the latents\n",
    "    intermediate_latent_path = left_filename.parent / Path(\"latent_json_folder\") / Path(f\"latent_json_{new_filename}.json\")\n",
    "    with open(intermediate_latent_path, \"w\") as json_file:\n",
    "        json.dump(intermediate_latent.tolist(), json_file)\n",
    "\n",
    "    # Run image generation on this intermediate latent \n",
    "    mid_measure = txt_latent_ndarray_2_image(intermediate_latent, outdir=left_filename.parent, file_name=new_filename,\n",
    "                               display_image=False, delete_img=False, seed=seed, \n",
    "                               return_latent_ndarray = distance_metric==\"latents\",\n",
    "                               return_pixels = distance_metric==\"pixels\",\n",
    "                               return_filename = distance_metric==\"filesize\",\n",
    "                                            return_clip_embedding = distance_metric==\"clip_embeddings\")\n",
    "    if (distance_metric == \"filesize\"):\n",
    "        mid_measure = Path(mid_measure).stat().st_size\n",
    "\n",
    "    mid_filename = Path(left_filename.parent) / Path(new_filename+\".png\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # Calculate the new distance (depending on distance_metric and direction)\n",
    "    # ========================================================================\n",
    "\n",
    "    # Determine which two things we're using \n",
    "    if (direction == \"left\"):\n",
    "        new_left_measure = left_measure\n",
    "        new_right_measure = mid_measure\n",
    "        new_left_filepath = left_filename\n",
    "        new_right_filepath = mid_filename\n",
    "        new_left_latent = left_latent\n",
    "        new_right_latent = intermediate_latent\n",
    "    elif (direction == \"right\"):\n",
    "        new_left_measure = mid_measure\n",
    "        new_right_measure = right_measure\n",
    "        new_left_filepath = mid_filename\n",
    "        new_right_filepath = right_filename\n",
    "        new_left_latent = intermediate_latent\n",
    "        new_right_latent = right_latent\n",
    "\n",
    "\n",
    "    # Determine the distance between the new image and one of the side images depending on \n",
    "    # the direction, the distance metric, and whether the measure was provided\n",
    "    if (new_left_measure is not None and new_right_measure is not None):\n",
    "        distance_function = distance_metric_keys[distance_metric]\n",
    "        new_distance = distance_function(new_left_measure, new_right_measure)\n",
    "    else:\n",
    "        distance_function = distance_metric_keys[distance_metric + \"_paths\"]\n",
    "        new_distance = distance_function(new_left_filepath, new_right_filepath)\n",
    "\n",
    "\n",
    "    # If the percent change between the \n",
    "    if (new_distance > pct_change_threshold):\n",
    "        recursive_latent_interpolation(new_left_filepath, new_right_filepath, new_left_latent, new_right_latent, \n",
    "                                       left_measure=new_left_measure, right_measure=new_right_measure, direction=direction, \n",
    "                                       early_stop=early_stop-1, pct_change_threshold=pct_change_threshold, \n",
    "                                       distance_metric=distance_metric, seed=seed)\n",
    "        \n",
    "    # Return the midpoint filename\n",
    "    return mid_filename, mid_measure, intermediate_latent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c566f2d8-e264-4632-9322-9db7766af381",
   "metadata": {},
   "source": [
    "#### `prompt_graph_back_and_forth_recursion()`\n",
    "This method will perform leftwards and rightwards recursive latent interpolation on each of the images in a Prompt Graph output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3b5d616-1b98-4853-87ee-96334a3e3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will perform the back and forth recursion\n",
    "def prompt_graph_back_and_forth_recursion(prompt_graph_output_folder, loops=1, \n",
    "                                          pct_change_threshold=0.3, early_stop=4,\n",
    "                                          seed=1,\n",
    "                                          distance_metric=\"clip_embeddings\",\n",
    "                                          new_folder_suffix=\"smoother_interpolations\",\n",
    "                                          save_image_change_plot=True):\n",
    "    \n",
    "    # Ensure that prompt_graph_output_folder is a Path\n",
    "    prompt_graph_output_folder = Path(prompt_graph_output_folder)\n",
    "\n",
    "    # Make a copy of this folder that \n",
    "    prompt_graph_output_folder_parent = prompt_graph_output_folder.parent\n",
    "    new_output_folder = prompt_graph_output_folder_parent / Path(f\"{prompt_graph_output_folder.stem}_{new_folder_suffix}\")\n",
    "    if (new_output_folder.exists()):\n",
    "        shutil.rmtree(new_output_folder)\n",
    "    shutil.copytree(prompt_graph_output_folder, new_output_folder)\n",
    "\n",
    "    # Run through each of the loops\n",
    "    for loop in range(loops):\n",
    "\n",
    "        # Grab all of the .png paths in new_output_folder\n",
    "        file_path_list = os_sorted([path for path in list(new_output_folder.iterdir()) if path.suffix == \".png\"])\n",
    "\n",
    "        # Load in the latents for all of these images \n",
    "        latents_by_stem_dict = {}\n",
    "        for path in [Path(f'{str(new_output_folder / Path(\"latent_json_folder\"))}/latent_json_{path.stem}.json')\n",
    "                     for path in file_path_list]:\n",
    "            with open(path, \"r\") as json_file:\n",
    "                latents_by_stem_dict[path.stem.split(\"_\")[-1]] = np.asarray(json.load(json_file))\n",
    "\n",
    "        # Iterate through each of the files in the file_path_list, and run recursive_latent_interpolation\n",
    "        for idx, right_filename in tqdm(list(enumerate(file_path_list))):\n",
    "            if (idx == 0): continue\n",
    "\n",
    "            # Grab the left filename\n",
    "            left_filename = file_path_list[idx-1]\n",
    "\n",
    "            # Grab the CLIP latents for each of the files\n",
    "            left_latent = latents_by_stem_dict[left_filename.stem]\n",
    "            right_latent = latents_by_stem_dict[right_filename.stem]\n",
    "\n",
    "            # Grab the mesures of each of the files\n",
    "            if (distance_metric == \"latents\"):\n",
    "                left_measure = left_latent\n",
    "                right_measure = right_latent\n",
    "            elif (distance_metric == \"pixels\"):\n",
    "                left_measure = np.asarray(Image.open(left_filename))\n",
    "                right_measure = np.asarray(Image.open(right_filename))\n",
    "            elif (distance_metric == \"filesize\"):\n",
    "                left_measure = left_filename.stat().st_size\n",
    "                right_measure = right_filename.stat().st_size\n",
    "            elif (distance_metric == \"clip_embeddings\"):\n",
    "                left_measure = image_path_to_clip_embedding(left_filename)\n",
    "                right_measure = image_path_to_clip_embedding(right_filename)\n",
    "\n",
    "            # Now, grab the percent change between the left and the right measures\n",
    "            distance_function = distance_metric_keys[distance_metric]\n",
    "            pct_change = distance_function(left_measure, right_measure)\n",
    "\n",
    "            # If the change between this image and the previous one is higher than the threshold, run recursion\n",
    "            if (pct_change > pct_change_threshold):\n",
    "\n",
    "                # Run the recursive latent interpolation in the leftwards direction\n",
    "                mid_filename, mid_measure, mid_latent = recursive_latent_interpolation(\n",
    "                    left_filename, right_filename, left_latent, right_latent, \n",
    "                    left_measure=left_measure, right_measure=right_measure, direction=\"left\", \n",
    "                    early_stop=early_stop, pct_change_threshold=pct_change_threshold, \n",
    "                    distance_metric=distance_metric, seed=seed)\n",
    "\n",
    "                # Now, check to see if the distance between the mid and right files is bigger than the pct_change \n",
    "                mid_pct_change = distance_function(mid_measure, right_measure)\n",
    "\n",
    "                # If the mid_pct_change is greater than the threshold, we're going to run rightwards recursion\n",
    "                if (mid_pct_change > pct_change_threshold):\n",
    "\n",
    "                    # Run the recursive latent interpolation in the rightwards direction\n",
    "                    right_mid_filename, right_mid_measure, right_mid_latent = recursive_latent_interpolation(\n",
    "                        mid_filename, right_filename, mid_latent, right_latent, \n",
    "                        left_measure=mid_measure, right_measure=right_measure, direction=\"right\", \n",
    "                        early_stop=early_stop, pct_change_threshold=pct_change_threshold, \n",
    "                        distance_metric=distance_metric, seed=seed)\n",
    "                    \n",
    "        # Now that we're at the end of the loop, we can rename everything\n",
    "        rename_pics_in_folder_monotonically(new_output_folder, rename_clip_latent=True)\n",
    "        \n",
    "    # If the save_image_change_plot flag is True, then we'll save the image difference plot\n",
    "    if (save_image_change_plot):\n",
    "        \n",
    "        # Generate the prompt graph image difference figure\n",
    "        plotly_fig = generate_prompt_graph_image_difference_plotly_fig(Path(new_output_folder), \n",
    "                                                                       distance_method=distance_metric)\n",
    "        \n",
    "        # Determine what the filepath is \n",
    "        file_path = Path(new_output_folder) / Path(\"Frame to Frame Difference Graph.png\")\n",
    "        \n",
    "        # Now, save the Plotly figure that was just created\n",
    "        plotly_fig.write_image(file_path, format=\"png\", scale=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae75c2be-b603-4e86-93b1-ac7b223a8ed4",
   "metadata": {},
   "source": [
    "#### `generate_prompt_graph_animation()`\n",
    "The following method will create an animation from some prompt graph output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68cae80c-e48f-4113-ab41-cbc00ca56ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will create an animation at a given FPS from a Prompt Graph folder\n",
    "def generate_prompt_graph_animation(image_folder, fps=5):\n",
    "    \n",
    "    # Now, create the output file name\n",
    "    output_file_name = f\"animation_{fps}_fps.mp4\"\n",
    "    output_file_path = Path(image_folder) / Path(output_file_name)\n",
    "\n",
    "    # Generate the FFMPEG command\n",
    "    command = f\"ffmpeg -r {fps} -s 1280x720 -f image2 -i \\\"{image_folder}\\%d.png\\\" -vcodec libx264 -crf 25  -pix_fmt yuv420p -r {fps} \\\"{output_file_path}\\\"\"\n",
    "\n",
    "    # Print and run the FFMPEG command \n",
    "    subprocess.run(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b5a26-cc0c-4b16-b30b-78a2e1a14bdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Graphing Related Methods\n",
    "These methods specifically involve using Plotly to create graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d242317e-cacc-403e-bea8-613c05ad8cf7",
   "metadata": {},
   "source": [
    "#### `config_to_prompt_strength_df()`\n",
    "This method is a \"helper\" method for the `generate_prompt_graph_image()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2039e8f-448e-4ebc-91f8-1400b81b4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will create a prompt_strength_df \n",
    "def config_to_prompt_strength_df(config):\n",
    "    \n",
    "    # First, we'll create a dictionary of prompt key --> info for each of the prompts\n",
    "    prompt_key_to_prompt_info = {prompt_info[\"key\"]: prompt_info for prompt_info in config[\"prompts\"]}\n",
    "\n",
    "    # We're going to create a DataFrame out of these prompt_line_df_records.\n",
    "    prompt_line_df_records = []\n",
    "    for frame, prompt_key_to_strength in config[\"prompt_strength_by_frame\"].items():\n",
    "\n",
    "        # Check if there are non-null values in the prompt_key_to_strength dictionary\n",
    "        if ([x for x in [strength for prompt_key, strength in prompt_key_to_strength.items()] if x is not None]):\n",
    "\n",
    "            # Add a record for each of the non-null prompts\n",
    "            for key, strength in {int(prompt_key):float(strength) for \n",
    "                                         prompt_key, strength in prompt_key_to_strength.items() \n",
    "                                         if strength is not None}.items():\n",
    "\n",
    "                # Create a record for this (prompt, strength) instance\n",
    "                cur_prompt_strength_record = {\n",
    "                    \"key\": key,\n",
    "                    \"prompt\": prompt_key_to_prompt_info[key][\"prompt\"],\n",
    "                    \"strength\": strength,\n",
    "                    \"color\": prompt_key_to_prompt_info[key][\"color\"],\n",
    "                    \"frame\": int(frame)\n",
    "                }\n",
    "\n",
    "                # Now, add this record to the prompt_line_df_records list \n",
    "                prompt_line_df_records.append(cur_prompt_strength_record)\n",
    "\n",
    "    # Create the DataFrame and return it\n",
    "    prompt_strength_df = pd.DataFrame.from_records(prompt_line_df_records)\n",
    "    prompt_strength_df[\"frame\"] = prompt_strength_df[\"frame\"] - prompt_strength_df[\"frame\"].min()\n",
    "    return prompt_strength_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b1c98b-917e-4ef9-a5e8-8c3f7fa1627a",
   "metadata": {},
   "source": [
    "#### `generate_prompt_graph_plotly_fig()`\n",
    "\n",
    "This method will create a Plotly figure that contains the prompt strengths contained within a configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b598ad25-7def-4411-94ab-4b533d1c7748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will save the configuration image \n",
    "def generate_prompt_graph_plotly_fig(config):\n",
    "    \n",
    "    # Grab the prompt_strength_df \n",
    "    prompt_strength_df = config_to_prompt_strength_df(config)\n",
    "    \n",
    "    # Truncate the prompts (better labelling)\n",
    "    # This method will insert \"<br>\" into a string after every 100 characters\n",
    "    def break_string_into_lines_plotly(my_str, line_max_length=80):\n",
    "        lines = []\n",
    "        cur_line = \"\"\n",
    "        split_str = my_str.split(\" \")\n",
    "        for token in split_str:\n",
    "            if len(cur_line + f\" {token}\") <= line_max_length:\n",
    "                cur_line = cur_line + f\" {token}\"\n",
    "            else:\n",
    "                lines.append(cur_line.strip())\n",
    "                cur_line = token\n",
    "        lines.append(cur_line.strip())\n",
    "        breaked_lines = \"<br>\".join(lines)\n",
    "        return breaked_lines\n",
    "    n = 130\n",
    "    prompt_strength_df[\"prompt\"] = prompt_strength_df[\"prompt\"].apply(lambda x: break_string_into_lines_plotly(x, n))\n",
    "    line_ct = len(prompt_strength_df[\"prompt\"].unique()) + \"\".join(list(prompt_strength_df[\"prompt\"].unique())).count(\"<br>\")\n",
    "    y_offset = (line_ct * 19)/600\n",
    "    \n",
    "    # Create the figure\n",
    "    fig = px.line(prompt_strength_df, x=\"frame\", y=\"strength\", color=\"prompt\",\n",
    "                  title=f\"Prompt Graph - '{config['filename']}'\",\n",
    "                  labels={\"strength\": \"Prompt Strength\", \"frame\": \"Animation Frame\", \"prompt\": \"Prompt\"},\n",
    "                  height=600)\n",
    "\n",
    "    # Stylize the figure\n",
    "    fig.update_xaxes(nticks=10, range=[0, prompt_strength_df[\"frame\"].max()])\n",
    "    fig.update_layout(legend=dict(\n",
    "        orientation=\"h\",\n",
    "        y=-1*y_offset,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        title={\"text\": None}\n",
    "    ))\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96549274-a82e-4e63-872f-7babd81be8b1",
   "metadata": {},
   "source": [
    "#### `generate_prompt_graph_image_difference_plotly_fig()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc6493d3-ce2c-4703-b06c-7d553043df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will generate the \"change over time\" figure \n",
    "def generate_prompt_graph_image_difference_plotly_fig(path_to_img_folder, distance_method=\"latents\"):\n",
    "    \n",
    "    # Make sure that the path_to_img_folder is a Path object \n",
    "    path_to_img_folder = Path(path_to_img_folder)\n",
    "    \n",
    "    # We're going to create a DataFrame out of some of the information we extract from the files\n",
    "    file_info_df_records = []\n",
    "\n",
    "    # Iterating through each of the files\n",
    "    for file_path in path_to_img_folder.iterdir():\n",
    "\n",
    "        # Look for .png files\n",
    "        if (file_path.suffix != \".png\"): continue\n",
    "\n",
    "        # Grab the \"frame number\" that this file represents\n",
    "        frame_number = int(file_path.stem)\n",
    "\n",
    "        # Add this information to the records list\n",
    "        file_info_df_records.append({\n",
    "            \"file_path\": str(file_path),\n",
    "            \"frame_num\": frame_number,\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the records we'd created \n",
    "    file_info_df = pd.DataFrame(file_info_df_records).sort_values(\"frame_num\")\n",
    "\n",
    "    # Create the \"measure\" field within the file_info_df; creating this will depend on which distance metric we're using\n",
    "    if distance_method == \"filesize\": \n",
    "        file_info_df[\"measure\"] = file_info_df[\"file_path\"].apply(lambda x: Path(x).stat().st_size)\n",
    "    elif distance_method == \"pixels\": \n",
    "        file_info_df[\"measure\"] = file_info_df[\"file_path\"].apply(lambda x: np.asarray(Image.open(x)))\n",
    "    elif distance_method == \"latents\":\n",
    "        img_path_list = list(file_info_df[\"file_path\"])\n",
    "        img_latent_dict = img_path_list_to_latents(img_path_list)\n",
    "        img_latent_list = []\n",
    "        for path in img_path_list:\n",
    "            img_latent_list.append(img_latent_dict[Path(path).stem])\n",
    "        file_info_df[\"measure\"] = img_latent_list\n",
    "    elif distance_method == \"clip_embeddings\":\n",
    "        img_latent_dict = image_path_list_to_clip_embedding_dict(list(file_info_df[\"file_path\"]))\n",
    "        file_info_df[\"measure\"] = [img_latent_dict[Path(path).stem] for path in img_latent_dict]\n",
    "\n",
    "    # Now, create the \"difference between last frame\" field\n",
    "    diff_between_last_frame = []\n",
    "    for idx, row in enumerate(list(file_info_df.itertuples())):\n",
    "        if row.frame_num == 0:\n",
    "            diff_between_last_frame.append(0)\n",
    "        else:\n",
    "            prev_frame = file_info_df.query(\"frame_num==@row.frame_num-1\").iloc[0]\n",
    "            diff_between_last_frame.append(distance_metric_keys[distance_method](row.measure, prev_frame.measure))\n",
    "    file_info_df[\"change_between_frames\"] = diff_between_last_frame\n",
    "\n",
    "    # Finally, create the Plotly figure \n",
    "    file_size_diff_fig = px.bar(file_info_df.query(\"frame_num>0\"), x=\"frame_num\", y=\"change_between_frames\", \n",
    "                                labels={\"frame_num\": \"Frame\", \"change_between_frames\": \"Change From Previous Frame\"})\n",
    "    change_amt_dict = {\"filesize\": 1.1, \"latents\": 1.1, \"pixels\": 1.4, \"clip_embeddings\": 1.1}\n",
    "    file_size_diff_fig.update_yaxes(range=[0, file_info_df[\"change_between_frames\"].max()*change_amt_dict[distance_method]])\n",
    "    \n",
    "    # Return the figure \n",
    "    return file_size_diff_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d9c44-06a5-40fb-bc65-9aabff5141e5",
   "metadata": {},
   "source": [
    "# Testing Grounds\n",
    "Below, I'm going to test out some of the different methods that I've written. This will ensure that they're all working correctly! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3083435-deba-4059-b339-cfc10d17f7e8",
   "metadata": {},
   "source": [
    "### `txt_2_image()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df1eb0-f4bb-4aac-b775-7e00b48c4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = txt_2_image(\"cow:1 rainbow:1.5\", outdir=\"outputs/\", file_name=\"test\",\n",
    "                     return_latent_ndarray=True, display_image=True, delete_img=False, \n",
    "                     latent_json_output_path=\"outputs/latent_json.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1659b38e-b0a0-4438-851a-73e1ea822d91",
   "metadata": {},
   "source": [
    "### `txt_latent_ndarray_2_image()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c56b1-f48f-425a-b966-849ebdd322d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_latent_ndarray_2_image(latent, outdir=\"outputs/\", file_name=\"from_txt_latent_test\",\n",
    "                           display_image=True, delete_img=True, \n",
    "                           latent_json_output_path=\"outputs/latent_json_2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6276d9-5c3a-4f0f-8405-27bdafcb319d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ```txt_latent_path_2_image()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2b5cb-27a6-449f-8ad2-96a5ea623c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907ca62-178a-4c6b-aceb-9e2f9be61e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_latent_path_2_image(txt_latent_path, outdir=None, file_name=None, steps=55, height=512, width=512, seed=None, sample_amount=1, \n",
    "                       print_command=False, return_latent_ndarray=True, return_pixels=False, display_image=False, \n",
    "                       delete_img=False, turbo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746dd7e1-5e23-4b2c-832a-bbf97c48a77d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `img2latent()`\n",
    "Below, we're going to try and test the `img2latent()` method. This ought to take in the path to an image file and output a `.json` file that contains the latent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec7c3d-8d5f-448f-8c51-8f307ce57cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters, and then run the img_2_latent() method\n",
    "img_2_latent_test_path = \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\latent-clustering\\\\img_experiment_folders\\\\clip_sim_and_color_sim_interpolation\\\\5.png\"\n",
    "img_2_latent_outdir = \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\img2img-samples\\\\8\"\n",
    "img_2_latent_name = \"testName\"\n",
    "img_2_latent_ndarray = img_2_latent(img_2_latent_test_path, \n",
    "                                    outdir=img_2_latent_outdir, \n",
    "                                    name=img_2_latent_name, \n",
    "                                    return_ndarray=True,\n",
    "                                    delete_file=False)\n",
    "\n",
    "# Print the shape of the resulting latent in order to ensure that we'd correctly converted the image to a latent\n",
    "print(f\"The resulting latent has the following shape: {img_2_latent_ndarray.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b2838a-a8dc-4184-a66d-9fe239bbf36e",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### `img_folder_2_latents()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d34e04-79b6-4ac6-b149-9bbd2cb9742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder_2_latents_test_folder_path = \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\latent-clustering\\\\img_experiment_folders\\\\clip_sim_and_color_sim_interpolation\"\n",
    "ndarray_dict = img_folder_2_latents(img_folder_2_latents_test_folder_path, \n",
    "                                    delete_folder=True, return_ndarray_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45388ca1-f6e6-4c5d-a8b8-9e36bae12aaf",
   "metadata": {},
   "source": [
    "### `latent2img()`\n",
    "Next, we'll try and test the latent2img() method. This will take in the path to an image latent and create an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e60a0-8a4e-43b4-8f58-da138e380cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters, and then run the img_2_latent() method\n",
    "latent_2_img_path = \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\img2img-samples\\\\8\\\\testName.json\"\n",
    "latent_2_img_output_filepath = latent_2_img(latent_path=latent_2_img_path, return_path=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1dd6ec-1470-4056-af6b-6755d5e17b3a",
   "metadata": {},
   "source": [
    "We can also try running the `latent_2_img()` method by directly passing an image as an ndarray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdda9f6-da1c-47d6-99a3-e5906588ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_2_img_output_filepath = latent_2_img(img_latent_ndarray=img_2_latent_ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a06575d-1025-49d7-a2ce-9fbf1b8c0295",
   "metadata": {},
   "source": [
    "### `average_img_latents_from_path_list()`\n",
    "This function is meant to combine the latents of multiple images when passed a list of image paths. It'll return the ndarray of the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ddc92-92dd-4c36-b846-8879b5510a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of images we want to \"average\" together\n",
    "img_file_path_list = [\"C:\\\\Data\\\\Personal Study\\\\Programming\\\\stable-diffusion\\\\stable-diffusion-basujindal\\\\outputs\\\\txt2img-samples\\\\donwood seed experiment\\\\135.png\",\n",
    "                      \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\stable-diffusion\\\\stable-diffusion-basujindal\\\\outputs\\\\txt2img-samples\\\\donwood seed experiment\\\\136.png\"]\n",
    "\n",
    "# Run the latent averaging\n",
    "avg_latent_ndarray = average_img_latents_from_path_list(img_file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110494b9-5b7b-4dc3-969c-92c739c06a50",
   "metadata": {},
   "source": [
    "Now that we've averaged these together, we can try and create the image from the resulting ndarray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2243d39-8a50-42c2-b696-70b12d0dce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run latent_2_img, and display the resulting image. Delete the file itself once you're finished \n",
    "latent_2_img(img_latent_ndarray=avg_latent_ndarray, display_image=True, delete_file=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a694e-62d9-4cf7-99b0-0c6e172227c9",
   "metadata": {},
   "source": [
    "### `img_path_list_to_latents()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508f4ba-2b30-4c44-b3ee-d93d8f8f4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a list of image paths \n",
    "img_path_list_to_latents_test_path_list = [\n",
    "    \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\latent-clustering\\\\img_experiment_folders\\\\clip_sim_and_color_sim_interpolation\\\\28.png\",\n",
    "    \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\latent-clustering\\\\img_experiment_folders\\\\clip_sim_and_color_sim_interpolation\\\\33.png\",\n",
    "    \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\stable-diffusion\\\\stable-diffusion-basujindal\\\\outputs\\\\txt2img-samples\\\\donwood seed experiment\\\\42.png\"\n",
    "]\n",
    "\n",
    "# Now, grab the latents in a dictionary\n",
    "img_path_to_latents_dict = img_path_list_to_latents(img_path_list_to_latents_test_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd520e1-15fc-4c3e-b68f-48b63d9066e7",
   "metadata": {},
   "source": [
    "### `launch_config_generation()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06abe95-a628-487f-98ea-95f0821f65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"C:\\\\Users\\\\trevb\\\\Downloads\\\\Oh Uncertainty.json\"\n",
    "launch_config_generation(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935f07a-872e-4172-9a94-af9604386b18",
   "metadata": {},
   "source": [
    "### `change_in_filesize_paths()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e224278-53c8-415f-b3bc-5a767cdbe04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1_path = \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\latent-clustering\\\\img_experiment_folders\\\\clip_sim_and_color_sim_interpolation\\\\28.png\"\n",
    "file_2_path = \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\latent-clustering\\\\img_experiment_folders\\\\clip_sim_and_color_sim_interpolation\\\\33.png\"\n",
    "change_in_filesize_paths(file_1_path, file_2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81f3df-bdc2-408c-b8d4-14565074bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_in_filesize(file_1_path, file_1_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a211f6-2748-44b6-89af-0b03003f53c5",
   "metadata": {},
   "source": [
    "### `change_in_pixels_paths()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a5ee8-1d5e-4a9f-8abe-a4cbba358ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_in_pixels_paths(file_1_path, file_2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5221aff-069b-4c56-aaf9-ef134fcf69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_in_pixels_paths(file_2_path, file_1_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7658ae4-8c6c-4a84-83c4-16f8e2dc4bf2",
   "metadata": {},
   "source": [
    "### `recursive_latent_interpolation()`\n",
    "I'm going to test that the recursive latent interpolation function is working properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e93ea-76b4-4d9a-95f4-64f13e7258a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate some of the arguments \n",
    "early_stop = 5\n",
    "pct_change_threshold = 0.25\n",
    "direction = \"left\"\n",
    "distance_metric = \"latents\"\n",
    "seed = 1\n",
    "left_measure = left_latent\n",
    "right_measure = right_latent\n",
    "\n",
    "# Indicating a couple of different pieces of info \n",
    "frame_1 = 6\n",
    "frame_2 = 10\n",
    "left_filename = Path(f\"C:\\\\Data\\\\Personal Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\txt2img-samples\\\\Oh Uncertainty\\\\{frame_1}.png\")\n",
    "right_filename = Path(f\"C:\\\\Data\\\\Personal Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\txt2img-samples\\\\Oh Uncertainty\\\\{frame_2}.png\")\n",
    "left_latent = txt_latent_path_2_image(f\"C:\\\\Data\\\\Personal Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\txt2img-samples\\\\Oh Uncertainty\\\\latent_json_{frame_1}.json\",\n",
    "                                      outdir=left_filename.parent, file_name=left_filename.stem, seed=seed)\n",
    "right_latent = txt_latent_path_2_image(f\"C:\\\\Data\\\\Personal Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\txt2img-samples\\\\Oh Uncertainty\\\\latent_json_{frame_2}.json\",\n",
    "                                       outdir=right_filename.parent, file_name=right_filename.stem, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3fb53-6518-4c7f-9fe2-63128ebb30a2",
   "metadata": {},
   "source": [
    "Now, we'll run the recursive latent interpolation! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62c640-d36d-48d6-bc8f-5967da016439",
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_latent_interpolation(left_filename, right_filename, left_latent, right_latent, \n",
    "                               left_measure=left_measure, right_measure=right_measure, direction=\"left\", early_stop=early_stop, \n",
    "                               pct_change_threshold=pct_change_threshold, distance_metric=distance_metric, seed=seed)\n",
    "\n",
    "recursive_latent_interpolation(left_filename, right_filename, left_latent, right_latent, \n",
    "                               left_measure=left_measure, right_measure=right_measure, direction=\"right\", early_stop=early_stop, \n",
    "                               pct_change_threshold=pct_change_threshold, distance_metric=distance_metric, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3bf31-ff18-413d-b82b-eead4627009f",
   "metadata": {},
   "source": [
    "### `prompt_graph_back_and_forth_recursion()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca6b75-4baa-4cc2-af00-bd99c9e29934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicating a couple of pieces of information that will \"spoof\" arguments being passed\n",
    "prompt_graph_output_folder = \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\txt2img-samples\\\\Oh Uncertainty\"\n",
    "loops=1\n",
    "pct_change_threshold=0.1\n",
    "early_stop=4\n",
    "distance_metric = \"latents\"\n",
    "seed=1\n",
    "new_folder_suffix=\"_smoother_interpolations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e156e-0ce1-46ce-88d8-a6e7c3584926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this prompt graph back and forth\n",
    "prompt_graph_back_and_forth_recursion(prompt_graph_output_folder, loops=loops, \n",
    "                                      pct_change_threshold=pct_change_threshold, early_stop=early_stop,\n",
    "                                      seed=seed, distance_metric=distance_metric, new_folder_suffix=new_folder_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce61dba-e98b-4d55-84d2-555c1a339111",
   "metadata": {},
   "source": [
    "### `generate_prompt_graph_plotly_fig()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f411c7-31dd-40d4-bc4e-aa93e5204051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spoofing some of the arguments\n",
    "image_folder = \"D:\\\\Personal-Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\txt2img-samples\\\\All Seeing Eye of God\"\n",
    "\n",
    "# Loading in the config\n",
    "with open(f\"{image_folder}/config.json\", \"r\") as json_file:\n",
    "    config_contents = json.load(json_file)\n",
    "    \n",
    "# Creating the plotly figure \n",
    "plotly_fig = generate_prompt_graph_image(config_contents)\n",
    "plotly_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b403ad-228b-4140-abc2-930cacfa5318",
   "metadata": {},
   "source": [
    "### `generate_prompt_graph_image_difference_plotly_fig()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d4ace4f-e8f5-41c5-bc67-428771ca47f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Frame=%{x}<br>Change From Previous Frame=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38
         ],
         "xaxis": "x",
         "y": [
          0.1295682191848755,
          0.012108325958251953,
          0.025560855865478516,
          0.022894561290740967,
          0.03586888313293457,
          0.007272183895111084,
          0.04381221532821655,
          0.02173483371734619,
          0.0123291015625,
          0.022142648696899414,
          0.03372412919998169,
          0.016975760459899902,
          0.03787106275558472,
          0.02976369857788086,
          0.05268847942352295,
          0.30940723419189453,
          0.08358246088027954,
          0.047217369079589844,
          0.10039007663726807,
          0.006988883018493652,
          0.04443693161010742,
          0.008870482444763184,
          0.0277826189994812,
          0.010188519954681396,
          0.027572274208068848,
          0.6522760689258575,
          0.08930271863937378,
          0.268060564994812,
          0.08803671598434448,
          0.16757732629776,
          0.07029354572296143,
          0.05274033546447754,
          0.05284696817398071,
          0.06983482837677002,
          0.04783761501312256,
          0.06403720378875732,
          0.029034078121185303,
          0.046441078186035156
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": true,
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0.5,
          38.5
         ],
         "title": {
          "text": "Frame"
         },
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          0.7175036758184433
         ],
         "title": {
          "text": "Change From Previous Frame"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"e5de2023-8509-40a1-a61d-54388288c23b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e5de2023-8509-40a1-a61d-54388288c23b\")) {                    Plotly.newPlot(                        \"e5de2023-8509-40a1-a61d-54388288c23b\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Frame=%{x}<br>Change From Previous Frame=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38],\"xaxis\":\"x\",\"y\":[0.1295682191848755,0.012108325958251953,0.025560855865478516,0.022894561290740967,0.03586888313293457,0.007272183895111084,0.04381221532821655,0.02173483371734619,0.0123291015625,0.022142648696899414,0.03372412919998169,0.016975760459899902,0.03787106275558472,0.02976369857788086,0.05268847942352295,0.30940723419189453,0.08358246088027954,0.047217369079589844,0.10039007663726807,0.006988883018493652,0.04443693161010742,0.008870482444763184,0.0277826189994812,0.010188519954681396,0.027572274208068848,0.6522760689258575,0.08930271863937378,0.268060564994812,0.08803671598434448,0.16757732629776,0.07029354572296143,0.05274033546447754,0.05284696817398071,0.06983482837677002,0.04783761501312256,0.06403720378875732,0.029034078121185303,0.046441078186035156],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frame\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Change From Previous Frame\"},\"range\":[0,0.7175036758184433]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e5de2023-8509-40a1-a61d-54388288c23b');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SPOOF\n",
    "# Indicating where your diffusion image sequence is\n",
    "image_folder = Path(\"D:\\\\Personal-Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\txt2img-samples\\\\All Seeing Eye of God\")\n",
    "path_to_img_folder = image_folder\n",
    "distance_method = \"clip_embeddings\"\n",
    "generate_prompt_graph_image_difference_plotly_fig(image_folder, distance_method=distance_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029f6a3-a27c-488d-9a22-cb6822b7d445",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff257c9-a2aa-4033-a2a4-04176bcefe85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Averaging Many Images\n",
    "I've got a folder of about ~40 similar images. What does their \"average\" look like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18510bc6-19e1-4aa5-aaf7-8d24ec3cd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the path to a folder with a lot of images\n",
    "image_folder_path = \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\latent-clustering\\\\img_experiment_folders\\\\clip_sim_and_color_sim_interpolation\"\n",
    "\n",
    "# Calculate latents from each of the images in this folder, and return the average image latent\n",
    "avg_folder_latent = average_img_latents_from_img_folder(image_folder_path)\n",
    "\n",
    "# Display the image corresponding with this average latent\n",
    "latent_2_img(img_latent_ndarray=avg_folder_latent, display_image=True, delete_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb07cebc-87d9-4e57-a458-7c5bcc57d967",
   "metadata": {},
   "source": [
    "Well... that's a little disappointing, but not unexpected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681c905-76fe-4372-81d6-04eb3acb929f",
   "metadata": {},
   "source": [
    "### Prompt Graph - Initial Generation and Latent Recursion\n",
    "First, I'm going to launch the initial generation of the config file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7df027-3099-4a70-96de-b77f805aec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 6\n",
    "config_path = \"C:\\\\Users\\\\trevb\\\\Downloads\\\\All Seeing Eye of God.json\"\n",
    "output_path = launch_config_generation(config_path, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b86ca90-a513-4503-a8de-3b9a695dfbd6",
   "metadata": {},
   "source": [
    "Next, I'm going to run the latent interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669afaff-b484-485e-b1d2-482d7236902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path / Path(\"_smoother_interpolations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e9253-e397-4160-bf7a-5abe95c923a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this prompt graph back and forth\n",
    "prompt_graph_back_and_forth_recursion(output_path, loops=3, pct_change_threshold=0.045, early_stop=2,\n",
    "                                      seed=seed, distance_metric=\"latents\", new_folder_suffix=\"smoother_interpolations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48071b8-47e6-4b04-b246-ba801ab0b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this prompt graph back and forth\n",
    "prompt_graph_back_and_forth_recursion(str(output_path)+\"_smoother_interpolations\", loops=3, pct_change_threshold=0.03, early_stop=2,\n",
    "                                      seed=seed, distance_metric=\"latents\", new_folder_suffix=\"smoother_interpolations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684f7d8-1e5b-4725-bc35-3c4d3e0c664c",
   "metadata": {},
   "source": [
    "### OpenCLIP Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3634cdd-fe62-43da-b60d-3f04ce536deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b756018-f96b-4e30-998e-bc8c2de0288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicating which image we want to encode\n",
    "image_to_encode_path_list = [\"D:\\\\Personal-Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\txt2img-samples\\\\All Seeing Eye of God\\\\0.png\",\n",
    "                             \"D:\\\\Personal-Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\txt2img-samples\\\\All Seeing Eye of God\\\\1.png\"]\n",
    "\n",
    "img_to_encode_embedding_dict = image_path_list_to_clip_embedding_dict(image_to_encode_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeee097-75e7-474b-affc-95667e57a12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6223fee6-8b0e-4fac-b3da-01dc43a953fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cosine(img_to_encode_embedding_dict[\"0\"][0], img_to_encode_embedding_dict[\"0\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852d84d-6e36-442b-adb3-e87dd29edd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_encode_embedding_dict[\"0\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499229c-1367-4462-9bce-b15314ebf9c7",
   "metadata": {},
   "source": [
    "### Miscellaneous\n",
    "Any random code can be found below! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a046c16-1fda-4a5c-b10b-928a4d1b5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_1 = \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\sd-prompt-graph\\\\stable-diffusion\\\\outputs\\\\img2img-samples\\\\latent2img_outputImg.png\"\n",
    "pic_2 = \"C:\\\\Data\\\\Personal Study\\\\Programming\\\\stable-diffusion\\\\stable-diffusion-basujindal\\\\outputs\\\\txt2img-samples\\\\donwood seed experiment\\\\28.png\"\n",
    "latent_2_img(img_latent_ndarray=average_img_latents_from_path_list([pic_1, pic_2]), \n",
    "             display_image=True, delete_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14d80a-cd22-4bb8-baf9-29dd85d0603c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
